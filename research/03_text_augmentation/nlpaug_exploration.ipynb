{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used as a base and support in the implementation of the nlpaug library for text augmentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in number a wkly comp to win fa cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>1</td>\n",
       "      <td>this is the numbernd time we have tried number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>0</td>\n",
       "      <td>will you b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>0</td>\n",
       "      <td>pity was in mood for that soany other suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>0</td>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message\n",
       "0            0  go until jurong point crazy available only in ...\n",
       "1            0                            ok lar joking wif u oni\n",
       "2            1  free entry in number a wkly comp to win fa cup...\n",
       "3            0        u dun say so early hor u c already then say\n",
       "4            0  nah i dont think he goes to usf he lives aroun...\n",
       "...        ...                                                ...\n",
       "5152         1  this is the numbernd time we have tried number...\n",
       "5153         0              will you b going to esplanade fr home\n",
       "5154         0  pity was in mood for that soany other suggestions\n",
       "5155         0  the guy did some bitching but i acted like id ...\n",
       "5156         0                          rofl its true to its name\n",
       "\n",
       "[5157 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/silver/df_cleantext_v0.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "from experiments_utils import print_and_highlight_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "sample = df['Message'].iloc[:5].astype(str).to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.word.context_word_embs as nawcwe\n",
    "import nlpaug.augmenter.word.word_embs as nawwe\n",
    "import nlpaug.augmenter.word.spelling as naws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyboardAug method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go \u001b[31m^ntip\u001b[39m jurong \u001b[31mpoib$\u001b[39m crazy available only in bugis n great world la e \u001b[31mHuffeR\u001b[39m \u001b[31mc(je\u001b[39m \u001b[31mhh4re\u001b[39m got \u001b[31mampTe\u001b[39m wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar \u001b[31mMok7ng\u001b[39m wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in number a wkly comp to win fa cup \u001b[31mfona<\u001b[39m tkts \u001b[31mnKNberZt\u001b[39m may number \u001b[31mteDG\u001b[39m fa to \u001b[31mnImbef\u001b[39m to receive \u001b[31men6r&\u001b[39m \u001b[31mq*wstipnstx\u001b[39m txt \u001b[31mrxt3tcA\u001b[39m \u001b[31mapp.6\u001b[39m \u001b[31mmumbRrovernuJNsgs\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31mewrlh\u001b[39m hor u c \u001b[31mSOreWdy\u001b[39m \u001b[31mGh@n\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i \u001b[31md0nf\u001b[39m \u001b[31m5hibk\u001b[39m he \u001b[31mBoec\u001b[39m to usf he lives around \u001b[31mysre\u001b[39m though \n"
     ]
    }
   ],
   "source": [
    "aug = nac.KeyboardAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "1. The original criteria decided to not focus on special chars nor numbers so the cleaning acted accordingly. These two params should be changed. Same for upper/lower chars. \n",
    "2. Many characters of each modified word are changed and the result doesn't look realistic imo. This augmenter technique creates unrealistic results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until \u001b[31mjirojg\u001b[39m point crazy available only in bugis n great world la e buffet \u001b[31mdone\u001b[39m there got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar \u001b[31mjokibt\u001b[39m wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free \u001b[31mwgtry\u001b[39m in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs \u001b[31maoppy\u001b[39m \u001b[31mnhmberlfefhumberc\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31mewtly\u001b[39m hor u c already \u001b[31mtjeg\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i \u001b[31mvong\u001b[39m \u001b[31myhijk\u001b[39m he goes to usf he lives around here though \n"
     ]
    }
   ],
   "source": [
    "aug = nac.KeyboardAug(aug_word_p=0.1, include_numeric=False, include_special_char=False, include_upper_case=False)\n",
    "augmented_texts = aug.augment(sample)\n",
    "\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "The misspellings are very hardcore and artificial. They don't make sense to me. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nac.KeyboardAug)\n",
    "# help(aug.augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpellingAug method\n",
    "\n",
    "This method substitutes word by spelling mistake words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31mgona\u001b[39m \u001b[31mutill\u001b[39m jurong \u001b[31mpiont\u001b[39m crazy available only \u001b[31mil\u001b[39m bugis n great \u001b[31mwould\u001b[39m la e buffet cine there got amore \u001b[31mwant\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mOK.\u001b[39m lar joking \u001b[31mwife\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mfrre\u001b[39m entry \u001b[31men\u001b[39m \u001b[31munmber\u001b[39m \u001b[31me\u001b[39m wkly comp to \u001b[31mwinn\u001b[39m fa cup \u001b[31mfinel\u001b[39m tkts numberst may \u001b[31mnambr\u001b[39m text fa \u001b[31mtoo.\u001b[39m number to \u001b[31mrecived\u001b[39m entry questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "\u001b[31myou\u001b[39m dun say \u001b[31ms\u001b[39m \u001b[31morly\u001b[39m hor u c already \u001b[31mthne\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i dont think he goes \u001b[31mtp\u001b[39m usf he lives \u001b[31mround\u001b[39m \u001b[31mherer\u001b[39m \u001b[31mthrough\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "aug = naws.SpellingAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "This method creates more realistic results than the previous technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go \u001b[31muntill\u001b[39m jurong point \u001b[31mcraezy\u001b[39m \u001b[31mavilable\u001b[39m \u001b[31monley\u001b[39m \u001b[31mjin\u001b[39m bugis n \u001b[31mgrea\u001b[39m world \u001b[31ma\u001b[39m e buffet \u001b[31mcinema\u001b[39m \u001b[31mtheve\u001b[39m \u001b[31mgat\u001b[39m amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mOK)][[...\u001b[39m lar \u001b[31mchocking\u001b[39m \u001b[31mwife\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mfreer\u001b[39m entry \u001b[31mith\u001b[39m number a wkly comp to win fa \u001b[31mcouple\u001b[39m \u001b[31mfinel\u001b[39m tkts numberst may \u001b[31mnumper\u001b[39m \u001b[31mtest\u001b[39m fa to \u001b[31mnuamber\u001b[39m \u001b[31mro\u001b[39m \u001b[31mrecidive\u001b[39m entry questionstd txt ratetcs \u001b[31mapple\u001b[39m numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "\u001b[31myou\u001b[39m dun \u001b[31msoy\u001b[39m so early \u001b[31mhot\u001b[39m \u001b[31myou\u001b[39m c \u001b[31malread\u001b[39m \u001b[31mthenk\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah \u001b[31mI’ve\u001b[39m \u001b[31mwon't\u001b[39m think \u001b[31mhs\u001b[39m goes \u001b[31mti\u001b[39m usf he \u001b[31mlivres\u001b[39m around \u001b[31mher\u001b[39m \u001b[31mthogh\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "aug = naws.SpellingAug(aug_p = 0.5)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. The results are way more realistic.\n",
    "2. The dictionary includes upper case that should be treated later on.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(naws.SpellingAug())\n",
    "# help(aug.augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynonymAug\n",
    "\n",
    "Substitute similar word according to WordNet/ PPDB synonym\n",
    "\n",
    "Default is WordNet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/maldu/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until jurong point \u001b[31mnutcase\u001b[39m available only in bugis n great world la e buffet cine there got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar joking wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 31\n",
      "free entry in number a wkly comp to \u001b[31mbring\u001b[39m \u001b[31mhome\u001b[39m \u001b[31mthe\u001b[39m \u001b[31mbacon\u001b[39m \u001b[31mfa\u001b[39m \u001b[31mcup\u001b[39m \u001b[31mfinal\u001b[39m \u001b[31mtkts\u001b[39m \u001b[31mnumberst\u001b[39m \u001b[31mmay\u001b[39m \u001b[31mnumber\u001b[39m \u001b[31mtext\u001b[39m \u001b[31mfa\u001b[39m \u001b[31mto\u001b[39m \u001b[31mnumeral\u001b[39m \u001b[31mto\u001b[39m \u001b[31mget\u001b[39m \u001b[31mentry\u001b[39m \u001b[31mquestionstd\u001b[39m \u001b[31mtxt\u001b[39m \u001b[31mratetcs\u001b[39m \u001b[31mapply\u001b[39m \u001b[31mnumberovernumbers\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 13\n",
      "u \u001b[31mgrayish\u001b[39m \u001b[31mbrown\u001b[39m \u001b[31msay\u001b[39m \u001b[31mso\u001b[39m \u001b[31mformer\u001b[39m \u001b[31mhor\u001b[39m \u001b[31mu\u001b[39m \u001b[31mone\u001b[39m \u001b[31mc\u001b[39m \u001b[31malready\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 15\n",
      "nah i dont think he goes to usf \u001b[31matomic\u001b[39m \u001b[31mnumber\u001b[39m \u001b[31m2\u001b[39m \u001b[31mlives\u001b[39m \u001b[31maround\u001b[39m \u001b[31mhere\u001b[39m \u001b[31mthough\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. Some add extra words and I don't understand why\n",
    "\n",
    "- Original: 11\n",
    "- u dun say so early hor u c already then say\n",
    "- Augmented: 12\n",
    "- u dun say so other hor u ampere second already then say \n",
    "\n",
    "2. Translations look more realistic to me \n",
    "3. Checking the params of the function it provides two databases of misspellings 'wordnet' and 'ppdb'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 23\n",
      "\u001b[31mhold\u001b[39m \u001b[31mup\u001b[39m \u001b[31muntil\u001b[39m \u001b[31mjurong\u001b[39m \u001b[31mhead\u001b[39m \u001b[31mcrazy\u001b[39m \u001b[31mavailable\u001b[39m \u001b[31monly\u001b[39m \u001b[31min\u001b[39m \u001b[31mbugis\u001b[39m \u001b[31mn\u001b[39m \u001b[31mgreat\u001b[39m \u001b[31mworld\u001b[39m \u001b[31mla\u001b[39m \u001b[31me\u001b[39m \u001b[31mbuffet\u001b[39m \u001b[31mcine\u001b[39m \u001b[31mat\u001b[39m \u001b[31mthat\u001b[39m \u001b[31mplace\u001b[39m \u001b[31mgot\u001b[39m \u001b[31mamore\u001b[39m \u001b[31mwat\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 9\n",
      "ok lar joking wif u \u001b[31moffice\u001b[39m \u001b[31mof\u001b[39m \u001b[31mnaval\u001b[39m \u001b[31mintelligence\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 30\n",
      "\u001b[31mloose\u001b[39m entry in \u001b[31mturn\u001b[39m a wkly \u001b[31mcomprehensive\u001b[39m \u001b[31mexamination\u001b[39m \u001b[31mto\u001b[39m \u001b[31mwin\u001b[39m \u001b[31mfa\u001b[39m \u001b[31mcup\u001b[39m \u001b[31mconcluding\u001b[39m \u001b[31mtkts\u001b[39m \u001b[31mnumberst\u001b[39m \u001b[31mcrataegus\u001b[39m \u001b[31mlaevigata\u001b[39m \u001b[31mnumber\u001b[39m \u001b[31mtext\u001b[39m \u001b[31mfa\u001b[39m to \u001b[31mnumber\u001b[39m \u001b[31mto\u001b[39m \u001b[31mreceive\u001b[39m \u001b[31mentry\u001b[39m \u001b[31mquestionstd\u001b[39m \u001b[31mtxt\u001b[39m \u001b[31mratetcs\u001b[39m \u001b[31mapply\u001b[39m \u001b[31mnumberovernumbers\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31mother\u001b[39m hor u c already \u001b[31mso\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 15\n",
      "nah i dont think \u001b[31matomic\u001b[39m \u001b[31mnumber\u001b[39m \u001b[31m2\u001b[39m \u001b[31mrifle\u001b[39m \u001b[31mto\u001b[39m \u001b[31musf\u001b[39m \u001b[31mhe\u001b[39m \u001b[31mgo\u001b[39m \u001b[31maround\u001b[39m \u001b[31mhere\u001b[39m \u001b[31mthough\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug(aug_p= 0.3)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "1. Indeed we should be careful with the perc of augmented texts because it adds new words changing the length of the sentence. \n",
    "2. Some synonims are not fitting the meaning of the sentence imo.\n",
    "\n",
    "This cannot be used unless we find a way to force 1-to-1 swapping...not even then. We should also restrict the type of synonym to swap to absolute synonyms :\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(naw.SynonymAug())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WordEmbeddingAug method\n",
    "\n",
    "This method inserts word randomly by word embeddings similarity. \n",
    "\n",
    ":param str model_type: Model type of word embeddings. Expected values include 'word2vec', 'glove' and 'fasttext'.\n",
    "\n",
    "### Download models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"./models\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM\n",
      "From (redirected): https://drive.google.com/uc?export=download&id=0B7XkCwpI5KDYNlNUTTlSS21pQmM&confirm=t&uuid=27125d57-52fa-401b-8a73-de9429426f8e\n",
      "To: /home/maldu/dscience/projects/spam_detector/research/03_text_augmentation/models/GoogleNews-vectors-negative300.bin.gz\n",
      "100%|██████████| 1.65G/1.65G [02:27<00:00, 11.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "from nlpaug.util.file.download import DownloadUtil\n",
    "\n",
    "DownloadUtil.download_word2vec(dest_dir='./models')\n",
    "DownloadUtil.download_glove('glove.6B', './models')\n",
    "DownloadUtil.download_fasttext('wiki-news-300d-1M', './models')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:14:20,279 - INFO - loading projection weights from ./models/GoogleNews-vectors-negative300.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:14:36,889 - INFO - KeyedVectors lifecycle event {'msg': 'loaded (3000000, 300) matrix of type float32 from ./models/GoogleNews-vectors-negative300.bin', 'binary': True, 'encoding': 'utf8', 'datetime': '2025-01-03T18:14:36.889408', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-50-generic-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31mwant\u001b[39m until jurong \u001b[31mJosh_Dotzler\u001b[39m crazy available \u001b[31mscarcely\u001b[39m in bugis n great world \u001b[31men_una\u001b[39m e buffet cine there got \u001b[31mla_musica\u001b[39m \u001b[31mmicheal\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mUmmmm\u001b[39m lar joking \u001b[31mgina\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mHEARING_LOSS_OUTREACH\u001b[39m entry \u001b[31mbefore\u001b[39m number a \u001b[31mavail_1Dec\u001b[39m \u001b[31mmcdonalds\u001b[39m to win \u001b[31missa\u001b[39m \u001b[31mCzech_Republic_Kveta_Peschke\u001b[39m final tkts numberst \u001b[31mmaynot\u001b[39m \u001b[31mboth\u001b[39m text fa to \u001b[31mgeographical_dispersion\u001b[39m to receive entry questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u \u001b[31mnamang\u001b[39m \u001b[31mtell_myEyewitnessNews.com\u001b[39m \u001b[31msoooo\u001b[39m early \u001b[31mhaga\u001b[39m u c already then say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah \u001b[31msth\u001b[39m \u001b[31mthier\u001b[39m think \u001b[31mresigning_El_Gamaty\u001b[39m goes to usf he lives \u001b[31mthrought\u001b[39m here though \n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path='./models/GoogleNews-vectors-negative300.bin',\n",
    "    action=\"substitute\")\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go \u001b[31mbefore\u001b[39m jurong point crazy available only in bugis n great \u001b[31mBritain\u001b[39m la e buffet cine \u001b[31mwhatsoever\u001b[39m \u001b[31mStates_Morovich\u001b[39m \u001b[31mtutti\u001b[39m \u001b[31mkom\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok \u001b[31mked\u001b[39m joking \u001b[31mjoanna\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mscoliosis_screenings\u001b[39m entry \u001b[31mover\u001b[39m \u001b[31mvarious\u001b[39m a \u001b[31mprkg\u001b[39m \u001b[31mnrl\u001b[39m to win \u001b[31mpo\u001b[39m cup final tkts numberst \u001b[31mdoesn_t\u001b[39m number text \u001b[31mba\u001b[39m to number to \u001b[31mgiving\u001b[39m entry questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun \u001b[31mworried\u001b[39m so \u001b[31mbegan\u001b[39m hor u \u001b[31m#.####-#_b\u001b[39m already \u001b[31mWhy_shouldn'tI\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i dont \u001b[31mfeel\u001b[39m \u001b[31mafterwards\u001b[39m \u001b[31mstays\u001b[39m to usf \u001b[31mhe'sa\u001b[39m lives around here though \n"
     ]
    }
   ],
   "source": [
    "aug = naw.WordEmbsAug(\n",
    "    model_type='word2vec', model_path='./models/GoogleNews-vectors-negative300.bin',\n",
    "    action=\"substitute\", aug_p= 0.3)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### glove 6B 100d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:15:09,195 - INFO - loading projection weights from ./models/glove.6B.100d.txt\n",
      "2025-01-03 18:15:24,849 - INFO - KeyedVectors lifecycle event {'msg': 'loaded (400000, 100) matrix of type float32 from ./models/glove.6B.100d.txt', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-01-03T18:15:24.849573', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-50-generic-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31myou\u001b[39m until jurong \u001b[31mmuch\u001b[39m crazy available only in bugis n great world la e buffet \u001b[31md'or\u001b[39m \u001b[31mthings\u001b[39m got \u001b[31mnaqoyqatsi\u001b[39m \u001b[31mprambanan\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31m'd\u001b[39m lar joking wif \u001b[31mω\u001b[39m oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in number \u001b[31mtake\u001b[39m wkly comp \u001b[31mseek\u001b[39m \u001b[31msecured\u001b[39m fa cup final \u001b[31mfukuchiyama\u001b[39m numberst \u001b[31mend\u001b[39m \u001b[31m12\u001b[39m text fa to \u001b[31mfour\u001b[39m to \u001b[31msend\u001b[39m entry questionstd txt ratetcs \u001b[31mable\u001b[39m numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31mprior\u001b[39m \u001b[31mmeer\u001b[39m u \u001b[31msimmons\u001b[39m \u001b[31mhave\u001b[39m then say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "\u001b[31meh\u001b[39m i dont \u001b[31mindeed\u001b[39m he goes to usf \u001b[31mthough\u001b[39m lives \u001b[31mnearby\u001b[39m here though \n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='glove', model_path='./models/glove.6B.100d.txt',\n",
    "    action=\"substitute\")\n",
    "augmented_texts = aug.augment(sample)\n",
    "\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until jurong point \u001b[31msomething\u001b[39m \u001b[31mdvd\u001b[39m only in \u001b[31mkaranga\u001b[39m n great world la \u001b[31mblog\u001b[39m buffet cine there got \u001b[31mloca\u001b[39m \u001b[31mbhagavathi\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok \u001b[31mpra\u001b[39m joking wif \u001b[31myang\u001b[39m oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in \u001b[31mthough\u001b[39m a wkly comp to win \u001b[31mwembley\u001b[39m \u001b[31mwinner\u001b[39m \u001b[31mopening\u001b[39m \u001b[31mwhifflet\u001b[39m numberst \u001b[31mfall\u001b[39m \u001b[31mleast\u001b[39m \u001b[31mbook\u001b[39m fa \u001b[31mattempt\u001b[39m number to receive entry questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u \u001b[31mstehf\u001b[39m say so early hor \u001b[31mje\u001b[39m \u001b[31m20\u001b[39m already then \u001b[31myou\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah \u001b[31mhere\u001b[39m \u001b[31m’ve\u001b[39m think he \u001b[31mnext\u001b[39m to usf \u001b[31madmitted\u001b[39m lives around here though \n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='glove', model_path='./models/glove.6B.100d.txt',\n",
    "    action=\"substitute\",  aug_p= 0.3)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:15:42,896 - INFO - loading projection weights from ./models/wiki-news-300d-1M.vec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-03 18:17:30,377 - INFO - KeyedVectors lifecycle event {'msg': 'loaded (999994, 300) matrix of type float32 from ./models/wiki-news-300d-1M.vec', 'binary': False, 'encoding': 'utf8', 'datetime': '2025-01-03T18:17:30.377731', 'gensim': '4.3.3', 'python': '3.10.12 (main, Nov  6 2024, 20:22:13) [GCC 11.4.0]', 'platform': 'Linux-6.8.0-50-generic-x86_64-with-glibc2.35', 'event': 'load_word2vec_format'}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until jurong point \u001b[31mhysterical\u001b[39m available \u001b[31mstill\u001b[39m in bugis n \u001b[31madmirable\u001b[39m world \u001b[31mdella\u001b[39m e \u001b[31mdinners\u001b[39m cine \u001b[31mthey\u001b[39m got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok \u001b[31mdoc-\u001b[39m joking \u001b[31myeer\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mopen\u001b[39m \u001b[31mposting\u001b[39m \u001b[31mplaying\u001b[39m number a wkly comp to win fa \u001b[31mvase\u001b[39m \u001b[31m5th\u001b[39m tkts numberst may \u001b[31mNumbers\u001b[39m text fa \u001b[31mmoving\u001b[39m number to \u001b[31mgarner\u001b[39m \u001b[31mform\u001b[39m questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u \u001b[31mneedin\u001b[39m say so \u001b[31mearly-to-mid\u001b[39m \u001b[31meet\u001b[39m u c already then \u001b[31msee\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah \u001b[31mmore.I\u001b[39m \u001b[31mdonnot\u001b[39m think he goes to \u001b[31mwww.yerelnet.org.tr\u001b[39m he lives around \u001b[31msure\u001b[39m though \n"
     ]
    }
   ],
   "source": [
    "aug = naw.WordEmbsAug(\n",
    "    model_type='fasttext', model_path='./models/wiki-news-300d-1M.vec',\n",
    "    action=\"substitute\")\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31mreach\u001b[39m until jurong point \u001b[31mderanged\u001b[39m available only in bugis n \u001b[31mHUGE\u001b[39m \u001b[31msport\u001b[39m la e \u001b[31meating\u001b[39m cine \u001b[31manyhow\u001b[39m got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok \u001b[31mlous\u001b[39m joking \u001b[31mcoc\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mzero-cost\u001b[39m \u001b[31mcopy\u001b[39m in number \u001b[31mover\u001b[39m wkly \u001b[31mUni\u001b[39m to win fa \u001b[31mVase\u001b[39m final tkts numberst may \u001b[31m119\u001b[39m text fa to \u001b[31m89\u001b[39m to \u001b[31mdistribute\u001b[39m \u001b[31mattempt\u001b[39m questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u \u001b[31mowt\u001b[39m \u001b[31mthough\u001b[39m \u001b[31m--so\u001b[39m early \u001b[31msoun\u001b[39m u c already then say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "\u001b[31mOhhhhhh\u001b[39m \u001b[31myoui\u001b[39m dont \u001b[31mdunno\u001b[39m he goes to usf he lives \u001b[31mround\u001b[39m here though \n"
     ]
    }
   ],
   "source": [
    "\n",
    "aug = naw.WordEmbsAug(\n",
    "    model_type='fasttext', model_path='./models/wiki-news-300d-1M.vec',\n",
    "    action=\"substitute\", aug_p= 0.3)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- It's always nice to try but this time we weren't succesful. None of three models made substitutions that would make sense. That is expected since our texts are rather short and there is not much semantic meaning on them. Augmentation based on keywords provided better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(naw.WordEmbsAug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ContextualWordEmbs method\n",
    "\n",
    "I'll try SqueezeBERT since the resources are limited "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "486e1f47d6f54a94a8954f24e739e7d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebbc895718314bdbbf95cfef020db727",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8a91ba8875d4688ac96a73c5f5f0751",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fda9299ff7a48bcaa523b3d79351f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1961cdc2565b4d7791bcf2dd2b71a344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31mreach\u001b[39m until jurong point \u001b[31mderanged\u001b[39m available only in bugis n \u001b[31mHUGE\u001b[39m \u001b[31msport\u001b[39m la e \u001b[31meating\u001b[39m cine \u001b[31manyhow\u001b[39m got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok \u001b[31mlous\u001b[39m joking \u001b[31mcoc\u001b[39m u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mzero-cost\u001b[39m \u001b[31mcopy\u001b[39m in number \u001b[31mover\u001b[39m wkly \u001b[31mUni\u001b[39m to win fa \u001b[31mVase\u001b[39m final tkts numberst may \u001b[31m119\u001b[39m text fa to \u001b[31m89\u001b[39m to \u001b[31mdistribute\u001b[39m \u001b[31mattempt\u001b[39m questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u \u001b[31mowt\u001b[39m \u001b[31mthough\u001b[39m \u001b[31m--so\u001b[39m early \u001b[31msoun\u001b[39m u c already then say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "\u001b[31mOhhhhhh\u001b[39m \u001b[31myoui\u001b[39m dont \u001b[31mdunno\u001b[39m he goes to usf he lives \u001b[31mround\u001b[39m here though \n"
     ]
    }
   ],
   "source": [
    "aug = naw.ContextualWordEmbsAug(\n",
    "    model_path='distilbert-base-uncased', action=\"substitute\", aug_p= 0.3)\n",
    "augmented_text = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go \u001b[31mgo\u001b[39m jurong \u001b[31mwent\u001b[39m crazy \u001b[31mbut\u001b[39m only in \u001b[31mcommercials\u001b[39m \u001b[31mlike\u001b[39m \u001b[31m[UNK]\u001b[39m \u001b[31msoup\u001b[39m \u001b[31m[UNK]\u001b[39m \u001b[31mmama\u001b[39m \u001b[31mdie\u001b[39m cine there got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 5\n",
      "\u001b[31mrv...\u001b[39m \u001b[31m≈\u001b[39m \u001b[31mה\u001b[39m \u001b[31m[UNK]\u001b[39m \u001b[31m≤\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in \u001b[31mserie\u001b[39m a wkly comp \u001b[31mweb\u001b[39m \u001b[31mview\u001b[39m fa \u001b[31mcups\u001b[39m final \u001b[31mround\u001b[39m \u001b[31mfixtures\u001b[39m may number text fa to \u001b[31mfifa\u001b[39m \u001b[31m11\u001b[39m receive entry \u001b[31mregistration\u001b[39m \u001b[31mrequest\u001b[39m ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 10\n",
      "\u001b[31mて\u001b[39m \u001b[31m我\u001b[39m \u001b[31m[UNK]\u001b[39m \u001b[31m•\u001b[39m early \u001b[31m…\u001b[39m \u001b[31m[UNK]\u001b[39m \u001b[31mblah...\u001b[39m \u001b[31mて\u001b[39m \u001b[31m！\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "\u001b[31m...\u001b[39m \u001b[31m…\u001b[39m \u001b[31m–\u001b[39m \u001b[31m…\u001b[39m he goes \u001b[31maround\u001b[39m \u001b[31mukraine\u001b[39m \u001b[31malways\u001b[39m \u001b[31mstops\u001b[39m \u001b[31mnear\u001b[39m \u001b[31mmoscow\u001b[39m though \n"
     ]
    }
   ],
   "source": [
    "aug = nawcwe.ContextualWordEmbsAug(\n",
    "    model_path='distilbert-base-uncased', \n",
    "    action ='substitute', \n",
    "    aug_p= 0.8)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "As with the word embeddings augmentation method, the results don't make much sense. It also adds simbols even from other languages. That could be restricted by params but after seeing the results I prefer to discard this method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nawcwe.ContextualWordEmbsAug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BackTranslationAug method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 33\n",
      "\u001b[31mGo\u001b[39m \u001b[31mto\u001b[39m jurong point crazy available only in bugis n great world la e buffet cine there got amore wat \u001b[31mwat\u001b[39m \u001b[31ma\u001b[39m \u001b[31mbugis\u001b[39m \u001b[31mn\u001b[39m \u001b[31mgreat\u001b[39m \u001b[31mworld\u001b[39m \u001b[31mes\u001b[39m \u001b[31mgot\u001b[39m \u001b[31mamore\u001b[39m \u001b[31mwat,\u001b[39m \u001b[31mthe\u001b[39m \u001b[31mbuffet\u001b[39m \u001b[31mc\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar \u001b[31mjokes\u001b[39m wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mFree\u001b[39m entry \u001b[31mto\u001b[39m number \u001b[31mone\u001b[39m wkly comp to win fa cup final tkts \u001b[31mnumbered\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mcan\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mcan\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mtext\u001b[39m \u001b[31mfa\u001b[39m \u001b[31mto\u001b[39m \u001b[31mnumbered\u001b[39m \u001b[31mfa\u001b[39m \u001b[31mnum\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 44\n",
      "u dun \u001b[31msag\u001b[39m so early hor u c \u001b[31msag\u001b[39m \u001b[31malready\u001b[39m say \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31malready\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31malready\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31malready\u001b[39m \u001b[31msay\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31mhor\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthat\u001b[39m \u001b[31myou\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthat\u001b[39m \u001b[31myou\u001b[39m \u001b[31msay\u001b[39m \u001b[31mthat\u001b[39m \u001b[31myou\u001b[39m \u001b[31mwill\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 14\n",
      "\u001b[31mI\u001b[39m \u001b[31mdon't\u001b[39m \u001b[31mthink\u001b[39m \u001b[31mhe's\u001b[39m \u001b[31mgoing\u001b[39m \u001b[31mto\u001b[39m \u001b[31mgo\u001b[39m \u001b[31mto\u001b[39m \u001b[31mthe\u001b[39m \u001b[31mUS\u001b[39m \u001b[31mif\u001b[39m \u001b[31mhe\u001b[39m \u001b[31mlives\u001b[39m \u001b[31mhere.\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "aug = naw.BackTranslationAug(\n",
    "    from_model_name='facebook/wmt19-en-de', \n",
    "    to_model_name='facebook/wmt19-de-en', \n",
    ")\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Go to jurong point crazy available only in bugis n great world la e buffet cine there got amore wat a bugis amore wat n great world it got amore wat a bugis amore wat n great world it got amore wat it got amore wat, the buffet, the buffet cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine cine it got amore crazy, until crazy, until it crazy, until it crazy, until go to go, until go, until go to go, go, go, go to go, go, go, go, go, go, go, go, go, go up to go, go, go, go, go, go, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go up, go only only only only only only, go, go, go, go up, go, go only only only only only only only go, go, go',\n",
       " 'ok lar jokes wif u oni',\n",
       " 'Free entry into number one wkly comp to win cup finals numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numbered numed numbered numbered numed numed numed numbered numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed numed',\n",
       " 'u dun sag so early hor u c sag already say then say already say then say already say then say say then say already say say then say hor say then say then say that you say that you say that you will not say that you will not say it, then you say it, then you say it, then you say it, then you say it, then you say it, then you say it, then you say it will say it will say it will say it will say it, then you say it, then you say it, then you say it it it it it, then it it it will say it it it, then it it it will say it will say it, then it it it it it, then it it it it it, then it it it it it it it it it it it, then it it it it it it, then it it it it it it it it, then it it it it it it it it it it it, then it it it it it it it it it it it it it it it, it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it it',\n",
       " \"I don't think he's going to go to the US if he lives here.\"]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "This method looks interesting but the length of the sentences is going out of control. \n",
    "\n",
    "EDIT: the is no way to force the same length in every sentence without modifying the augment class so this method is discarded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam-detector-P2ybB3t6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
