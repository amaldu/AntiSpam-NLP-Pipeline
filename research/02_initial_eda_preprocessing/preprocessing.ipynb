{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8495b5d4",
   "metadata": {},
   "source": [
    "The objective of this notebook is to perform the initial preprocessing on the dataset  in order to create a baseline model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e158e213",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06a4df8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02f92a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/maldu/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/maldu/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "from string import punctuation\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c3d43590",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>email</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get up to escapenumber escapenumber emergency ...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dear customer the pharmacy you shop at got too...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>please find below the gtv project status updat...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fuller harder\\nerectionsthe same as the one fr...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>thinking of breathing new life into your busin...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75936</th>\n",
       "      <td>we are grateful to all our devoted customers a...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75937</th>\n",
       "      <td>You have registered Sinco as Payee. Log in at ...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75938</th>\n",
       "      <td>seize the opportunity escapenumber anatrim esc...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75939</th>\n",
       "      <td>hi all attached is a patch that minimally enab...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75940</th>\n",
       "      <td>hi i am working on conjoint analysis how i can...</td>\n",
       "      <td>ham</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>75941 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   email label\n",
       "0      get up to escapenumber escapenumber emergency ...  spam\n",
       "1      dear customer the pharmacy you shop at got too...  spam\n",
       "2      please find below the gtv project status updat...   ham\n",
       "3      fuller harder\\nerectionsthe same as the one fr...  spam\n",
       "4      thinking of breathing new life into your busin...  spam\n",
       "...                                                  ...   ...\n",
       "75936  we are grateful to all our devoted customers a...  spam\n",
       "75937  You have registered Sinco as Payee. Log in at ...   ham\n",
       "75938  seize the opportunity escapenumber anatrim esc...  spam\n",
       "75939  hi all attached is a patch that minimally enab...   ham\n",
       "75940  hi i am working on conjoint analysis how i can...   ham\n",
       "\n",
       "[75941 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../../data/bronze/raw_train.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f02a8",
   "metadata": {},
   "source": [
    "## Change data types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a551a55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = df['label'].map({\"ham\": 0, \"spam\": 1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf36653",
   "metadata": {},
   "source": [
    "## Drop duplicated rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c66597",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd964d3",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "74b795e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [get, up, to, escapenumber, escapenumber, emer...\n",
       "1        [dear, customer, the, pharmacy, you, shop, at,...\n",
       "2        [please, find, below, the, gtv, project, statu...\n",
       "3        [fuller, harder, erectionsthe, same, as, the, ...\n",
       "4        [thinking, of, breathing, new, life, into, you...\n",
       "                               ...                        \n",
       "75936    [we, are, grateful, to, all, our, devoted, cus...\n",
       "75937    [You, have, registered, Sinco, as, Payee, ., L...\n",
       "75938    [seize, the, opportunity, escapenumber, anatri...\n",
       "75939    [hi, all, attached, is, a, patch, that, minima...\n",
       "75940    [hi, i, am, working, on, conjoint, analysis, h...\n",
       "Name: email, Length: 75606, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokenized = df.copy()\n",
    "df_tokenized['email'] = df_tokenized['email'].apply(word_tokenize)\n",
    "df_tokenized['email']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb53bb52",
   "metadata": {},
   "source": [
    "## Clean text function\n",
    "\n",
    "For more info visit the special_chars_analysis.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07dbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(tokens):\n",
    "    special_replacements = {\n",
    "        r\"£\": \"pound\",\n",
    "        r\"$\": \"dollar\",\n",
    "        r\"€\": \"euro\",\n",
    "        r\"%\": \"percentage\",\n",
    "        r\"♣\": \"clover\", \n",
    "        r\"®\": \"registered trademark\",\n",
    "        r\"©\": \"copyright\",\n",
    "        r\"☺\": \"emoji\",\n",
    "        r\"™\": \"trademark\",\n",
    "    }\n",
    "\n",
    "    # Chat words dictionary)\n",
    "    chat_words = {\n",
    "        \"afaik\": \"As Far As I Know\",\n",
    "        \"afk\": \"Away From Keyboard\",\n",
    "        \"asap\": \"As Soon As Possible\",\n",
    "        \"atk\": \"At The Keyboard\",\n",
    "        \"atm\": \"At The Moment\",\n",
    "        \"a3\": \"Anytime, Anywhere, Anyplace\",\n",
    "        \"bak\": \"Back At Keyboard\",\n",
    "        \"bbl\": \"Be Back Later\",\n",
    "        \"bbs\": \"Be Back Soon\",\n",
    "        \"bfn\": \"Bye For Now\",\n",
    "        \"b4n\": \"Bye For Now\",\n",
    "        \"brb\": \"Be Right Back\",\n",
    "        \"brt\": \"Be Right There\",\n",
    "        \"btw\": \"By The Way\",\n",
    "        \"b4\": \"Before\",\n",
    "        \"b4n\": \"Bye For Now\",\n",
    "        \"cu\": \"See You\",\n",
    "        \"cul8r\": \"See You Later\",\n",
    "        \"cya\": \"See You\",\n",
    "        \"faq\": \"Frequently Asked Questions\",\n",
    "        \"fc\": \"Fingers Crossed\",\n",
    "        \"fwiw\": \"For What It's Worth\",\n",
    "        \"fyi\": \"For Your Information\",\n",
    "        \"gal\": \"Get A Life\",\n",
    "        \"gg\": \"Good Game\",\n",
    "        \"gn\": \"Good Night\",\n",
    "        \"gmta\": \"Great Minds Think Alike\",\n",
    "        \"gr8\": \"Great!\",\n",
    "        \"g9\": \"Genius\",\n",
    "        \"ic\": \"I See\",\n",
    "        \"icq\": \"I Seek you (also a chat program)\",\n",
    "        \"ilu\": \"ILU: I Love You\",\n",
    "        \"imho\": \"In My Honest/Humble Opinion\",\n",
    "        \"imo\": \"In My Opinion\",\n",
    "        \"iow\": \"In Other Words\",\n",
    "        \"irl\": \"In Real Life\",\n",
    "        \"kiss\": \"Keep It Simple, Stupid\",\n",
    "        \"ldr\": \"Long Distance Relationship\",\n",
    "        \"lmao\": \"Laugh My A.. Off\",\n",
    "        \"lol\": \"Laughing Out Loud\",\n",
    "        \"ltns\": \"Long Time No See\",\n",
    "        \"l8r\": \"Later\",\n",
    "        \"mte\": \"My Thoughts Exactly\",\n",
    "        \"m8\": \"Mate\",\n",
    "        \"nrn\": \"No Reply Necessary\",\n",
    "        \"oic\": \"Oh I See\",\n",
    "        \"pita\": \"Pain In The A..\",\n",
    "        \"prt\": \"Party\",\n",
    "        \"prw\": \"Parents Are Watching\",\n",
    "        \"qpsa?\": \"Que Pasa?\",\n",
    "        \"rofl\": \"Rolling On The Floor Laughing\",\n",
    "        \"roflol\": \"Rolling On The Floor Laughing Out Loud\",\n",
    "        \"rotflmao\": \"Rolling On The Floor Laughing My A.. Off\",\n",
    "        \"sk8\": \"Skate\",\n",
    "        \"stats\": \"Your sex and age\",\n",
    "        \"asl\": \"Age, Sex, Location\",\n",
    "        \"thx\": \"Thank You\",\n",
    "        \"ttfn\": \"Ta-Ta For Now!\",\n",
    "        \"ttyl\": \"Talk To You Later\",\n",
    "        \"u\": \"You\",\n",
    "        \"u2\": \"You Too\",\n",
    "        \"u4e\": \"Yours For Ever\",\n",
    "        \"wb\": \"Welcome Back\",\n",
    "        \"wtf\": \"What The F...\",\n",
    "        \"wtg\": \"Way To Go!\",\n",
    "        \"wuf\": \"Where Are You From?\",\n",
    "        \"w8\": \"Wait...\",\n",
    "        \"7k\": \"Sick:-D Laugher\",\n",
    "        \"tfw\": \"That feeling when\",\n",
    "        \"mfw\": \"My face when\",\n",
    "        \"mrw\": \"My reaction when\",\n",
    "        \"ifyp\": \"I feel your pain\",\n",
    "        \"tntl\": \"Trying not to laugh\",\n",
    "        \"jk\": \"Just kidding\",\n",
    "        \"idc\": \"I don't care\",\n",
    "        \"ily\": \"I love you\",\n",
    "        \"imu\": \"I miss you\",\n",
    "        \"adih\": \"Another day in hell\",\n",
    "        \"zzz\": \"Sleeping, bored, tired\",\n",
    "        \"wywh\": \"Wish you were here\",\n",
    "        \"time\": \"Tears in my eyes\",\n",
    "        \"bae\": \"Before anyone else\",\n",
    "        \"fimh\": \"Forever in my heart\",\n",
    "        \"bsaaw\": \"Big smile and a wink\",\n",
    "        \"bwl\": \"Bursting with laughter\",\n",
    "        \"bff\": \"Best friends forever\",\n",
    "        \"csl\": \"Can't stop laughing\"\n",
    "    }\n",
    "\n",
    "    \n",
    "\n",
    "    emoticon_pattern = re.compile(r\"\"\"\n",
    "    [:;=Xx]           \n",
    "    [-~]?             \n",
    "    [\\)\\]\\(\\[dDpP/]   \n",
    "    \"\"\", re.VERBOSE)\n",
    "    \n",
    "    tokens = [re.sub(pattern, replacement, token) for token in tokens for pattern, replacement in special_replacements.items()]\n",
    "    tokens = [token.replace('\\n', ' ') for token in tokens]\n",
    "    tokens = [re.sub(emoticon_pattern, 'emoji', token) for token in tokens]\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    tokens = [re.sub(r'\\b' + re.escape(abbr) + r'\\b', full_form, token) for token in tokens for abbr, full_form in chat_words.items()]\n",
    "    tokens = [re.sub('<[^<>]+>', ' ', token) for token in tokens]\n",
    "    tokens = [re.sub(r'http\\S+|www.\\S+', '', token) for token in tokens]\n",
    "    tokens = [re.sub(r'[0-9]+', 'number', token) for token in tokens]\n",
    "    tokens = [re.sub(r'[^\\s]+@[^\\s]+', 'emailaddr', token) for token in tokens]\n",
    "    tokens = [token.translate(str.maketrans('', '', punctuation)) for token in tokens]\n",
    "    tokens = [re.sub(r'[^a-zA-Z\\s]', '', token) for token in tokens]\n",
    "    tokens = [re.sub(r'\\s+', ' ', token).strip() for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "\n",
    "\n",
    "df_tokenized['email'] = df_tokenized['email'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf8ead88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_tokenized.to_csv(\"../data/silver/df_cleantext_v0.csv\", index= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30ac7834",
   "metadata": {},
   "source": [
    "## Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c46c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(tokens):\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    return filtered_tokens\n",
    "\n",
    "df_text_clean = df_tokenized.copy()\n",
    "df_text_clean['message_clean'] = df_text_clean['email'].apply(remove_stopwords)\n",
    "df_text_clean['message_clean']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c41589",
   "metadata": {},
   "source": [
    "## Lemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c59f05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(tokens):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    return ' '.join(lemmatized_tokens) \n",
    "\n",
    "df_text_clean['message_lemmatized'] = df_text_clean['message_clean'].apply(lemmatize_text)\n",
    "df_text_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff39804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/silver/df_lemmatized_v0.csv\", index= False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2eb0349",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d99378",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (interview_preparation_bot)",
   "language": "python",
   "name": "interview_preparation_bot"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
