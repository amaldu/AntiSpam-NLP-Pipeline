{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will be used as a base and support in the implementation of the nlpaug library for text augmentation.\n",
    "\n",
    "\n",
    "Inspiration taken from : https://www.kaggle.com/code/andypenrose/text-augmentation-with-nlpaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>go until jurong point crazy available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>ok lar joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>free entry in number a wkly comp to win fa cup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>u dun say so early hor u c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>nah i dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5152</th>\n",
       "      <td>1</td>\n",
       "      <td>this is the numbernd time we have tried number...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5153</th>\n",
       "      <td>0</td>\n",
       "      <td>will you b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5154</th>\n",
       "      <td>0</td>\n",
       "      <td>pity was in mood for that soany other suggestions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5155</th>\n",
       "      <td>0</td>\n",
       "      <td>the guy did some bitching but i acted like id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5156</th>\n",
       "      <td>0</td>\n",
       "      <td>rofl its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5157 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Category                                            Message\n",
       "0            0  go until jurong point crazy available only in ...\n",
       "1            0                            ok lar joking wif u oni\n",
       "2            1  free entry in number a wkly comp to win fa cup...\n",
       "3            0        u dun say so early hor u c already then say\n",
       "4            0  nah i dont think he goes to usf he lives aroun...\n",
       "...        ...                                                ...\n",
       "5152         1  this is the numbernd time we have tried number...\n",
       "5153         0              will you b going to esplanade fr home\n",
       "5154         0  pity was in mood for that soany other suggestions\n",
       "5155         0  the guy did some bitching but i acted like id ...\n",
       "5156         0                          rofl its true to its name\n",
       "\n",
       "[5157 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"../../data/silver/df_cleantext_v0.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nlpaug.augmenter.char as nac\n",
    "import nlpaug.augmenter.word as naw\n",
    "import nlpaug.augmenter.word.context_word_embs as nawcwe\n",
    "import nlpaug.augmenter.word.word_embs as nawwe\n",
    "import nlpaug.augmenter.word.spelling as naws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(\"../utils\"))\n",
    "from experiments_utils import print_and_highlight_diff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chunk for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "sample = df['Message'].iloc[:5].astype(str).to_list()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KeyboardAug method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until jurong \u001b[31mpling\u001b[39m \u001b[31mcTaz^\u001b[39m \u001b[31mavxilaf>e\u001b[39m \u001b[31mon:T\u001b[39m in bugis n great world la e buffet cine \u001b[31mtTege\u001b[39m got \u001b[31mXmire\u001b[39m wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar \u001b[31mjok&hg\u001b[39m wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mb5ee\u001b[39m entry in \u001b[31mnjmbed\u001b[39m a \u001b[31mw.<y\u001b[39m \u001b[31mcojO\u001b[39m to win fa cup \u001b[31mvinaI\u001b[39m tkts \u001b[31mn*mb3rs5\u001b[39m may number \u001b[31mtsst\u001b[39m fa to number to \u001b[31mrecF(v$\u001b[39m entry questionstd txt ratetcs \u001b[31mzp9ly\u001b[39m numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31meW#ly\u001b[39m hor u c \u001b[31mal#eSdg\u001b[39m \u001b[31mfheb\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i dont \u001b[31mfMink\u001b[39m he goes to usf he \u001b[31m<iges\u001b[39m \u001b[31marLunr\u001b[39m \u001b[31mjerw\u001b[39m though \n"
     ]
    }
   ],
   "source": [
    "aug = nac.KeyboardAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "1. The original criteria decided to not focus on special chars nor numbers so the cleaning acted accordingly. These two params should be changed. Same for upper/lower chars. \n",
    "2. Many characters of each modified word are changed and the result doesn't look realistic imo. This augmenter technique creates unrealistic results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go \u001b[31muhtol\u001b[39m \u001b[31mjurogn\u001b[39m point crazy available only in bugis n great world la e buffet cine there got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "ok lar \u001b[31miokong\u001b[39m wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in number a \u001b[31msjly\u001b[39m comp to win fa cup final tkts numberst may number text fa to \u001b[31mnjjber\u001b[39m to receive entry questionstd txt ratetcs apply \u001b[31mmkmgeekverjumbers\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say so \u001b[31mexrlg\u001b[39m hor u c already \u001b[31mghwn\u001b[39m say \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i \u001b[31mfong\u001b[39m think he \u001b[31mglez\u001b[39m to usf he lives around here though \n"
     ]
    }
   ],
   "source": [
    "aug = nac.KeyboardAug(aug_word_p=0.1, include_numeric=False, include_special_char=False, include_upper_case=False)\n",
    "augmented_texts = aug.augment(sample)\n",
    "\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "The misspellings are very hardcore and artificial. They don't make sense to me. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(nac.KeyboardAug)\n",
    "# help(aug.augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SpellingAug method\n",
    "\n",
    "This method substitutes word by spelling mistake words dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "go until jurong point crazy available only in bugis \u001b[31mOn\u001b[39m \u001b[31mgteat\u001b[39m world \u001b[31ma\u001b[39m e \u001b[31mbuffe\u001b[39m cine there \u001b[31mgate.\u001b[39m amore \u001b[31mway\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mOK)][[...\u001b[39m lar joking wif \u001b[31mYou\u001b[39m oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "\u001b[31mfee\u001b[39m entry \u001b[31mlin\u001b[39m \u001b[31mnummber\u001b[39m \u001b[31mg\u001b[39m wkly comp \u001b[31mro\u001b[39m win fa cup \u001b[31mfinel\u001b[39m tkts numberst \u001b[31mMay\u001b[39m number \u001b[31mtex\u001b[39m fa \u001b[31mou\u001b[39m number to receive entry questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "u dun say \u001b[31msooo\u001b[39m \u001b[31meary\u001b[39m hor \u001b[31mYou\u001b[39m c already then \u001b[31msaid\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i dont think \u001b[31mhi\u001b[39m \u001b[31mges\u001b[39m to usf he \u001b[31mlivi\u001b[39m around here \u001b[31mthoug\u001b[39m \n"
     ]
    }
   ],
   "source": [
    "aug = naws.SpellingAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes: \n",
    "\n",
    "This method creates more realistic results than the previous technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 20\n",
      "\u001b[31mgoes\u001b[39m until jurong \u001b[31mopint\u001b[39m \u001b[31mcreasy\u001b[39m available only \u001b[31ming\u001b[39m bugis n \u001b[31mgreats\u001b[39m \u001b[31mworls\u001b[39m \u001b[31ma\u001b[39m \u001b[31ma\u001b[39m buffet \u001b[31mcinema\u001b[39m \u001b[31mwhere\u001b[39m got amore wat \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mof\u001b[39m lar \u001b[31mchocking\u001b[39m wif \u001b[31mYou\u001b[39m oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry \u001b[31mia\u001b[39m \u001b[31mnamber's\u001b[39m \u001b[31mde\u001b[39m wkly comp \u001b[31mty\u001b[39m win fa \u001b[31mcop\u001b[39m \u001b[31mfinel\u001b[39m tkts numberst \u001b[31mmays\u001b[39m \u001b[31mnamber\u001b[39m text fa to number \u001b[31mtu\u001b[39m receive entry questionstd txt ratetcs \u001b[31mAply\u001b[39m numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 11\n",
      "\u001b[31mYou\u001b[39m dun say \u001b[31msaw\u001b[39m early \u001b[31mhot\u001b[39m \u001b[31mYou\u001b[39m c \u001b[31malread\u001b[39m then \u001b[31msaying\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah \u001b[31mit\u001b[39m \u001b[31mwon't\u001b[39m think \u001b[31mhe'll\u001b[39m \u001b[31mgou\u001b[39m \u001b[31mtake\u001b[39m usf he lives \u001b[31marounth\u001b[39m \u001b[31mhera\u001b[39m though \n"
     ]
    }
   ],
   "source": [
    "aug = naws.SpellingAug(aug_p = 0.5)\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "1. The results are way more realistic.\n",
    "2. The dictionary includes upper case that should be treated later on.    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(naws.SpellingAug())\n",
    "# help(aug.augment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SynonymAug\n",
    "\n",
    "Substitute similar word according to WordNet/ PPDB synonym"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/maldu/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Original: 20\n",
      "go until jurong point crazy available only in bugis n great world la e buffet cine there got amore wat\n",
      "Augmented: 22\n",
      "\u001b[31mmove\u001b[39m until jurong \u001b[31mitem\u001b[39m crazy available only in bugis n \u001b[31mgravid\u001b[39m \u001b[31mhumans\u001b[39m \u001b[31matomic\u001b[39m \u001b[31mnumber\u001b[39m \u001b[31m57\u001b[39m \u001b[31me\u001b[39m \u001b[31mbuffet\u001b[39m \u001b[31mcine\u001b[39m \u001b[31mthere\u001b[39m \u001b[31mgot\u001b[39m \u001b[31mamore\u001b[39m \u001b[31mwat\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 6\n",
      "ok lar joking wif u oni\n",
      "Augmented: 6\n",
      "\u001b[31mo.k.\u001b[39m lar joking wif u oni \n",
      "--------------------------------------------------\n",
      "Original: 28\n",
      "free entry in number a wkly comp to win fa cup final tkts numberst may number text fa to number to receive entry questionstd txt ratetcs apply numberovernumbers\n",
      "Augmented: 28\n",
      "free entry in number a wkly comp to win fa cup \u001b[31mconcluding\u001b[39m tkts numberst may number text fa to number to \u001b[31mget\u001b[39m \u001b[31mentranceway\u001b[39m questionstd txt ratetcs apply numberovernumbers \n",
      "--------------------------------------------------\n",
      "Original: 11\n",
      "u dun say so early hor u c already then say\n",
      "Augmented: 12\n",
      "u dun say so \u001b[31mother\u001b[39m hor u \u001b[31mampere\u001b[39m \u001b[31msecond\u001b[39m \u001b[31malready\u001b[39m \u001b[31mthen\u001b[39m \u001b[31msay\u001b[39m \n",
      "--------------------------------------------------\n",
      "Original: 13\n",
      "nah i dont think he goes to usf he lives around here though\n",
      "Augmented: 13\n",
      "nah i dont \u001b[31mconceive\u001b[39m he \u001b[31mgo\u001b[39m to usf he lives \u001b[31mroughly\u001b[39m here though \n"
     ]
    }
   ],
   "source": [
    "aug = naw.SynonymAug()\n",
    "augmented_texts = aug.augment(sample)\n",
    "print_and_highlight_diff(sample, augmented_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "\n",
    "- Original: 11\n",
    "- u dun say so early hor u c already then say\n",
    "- Augmented: 12\n",
    "- u dun say so other hor u ampere second already then say \n",
    "\n",
    "some add extra words and I don't understand why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on SynonymAug in module nlpaug.augmenter.word.synonym object:\n",
      "\n",
      "class SynonymAug(nlpaug.augmenter.word.word_augmenter.WordAugmenter)\n",
      " |  SynonymAug(aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False, verbose=0)\n",
      " |  \n",
      " |  Augmenter that leverage semantic meaning to substitute word.\n",
      " |  \n",
      " |  :param str aug_src: Support 'wordnet' and 'ppdb' .\n",
      " |  :param str model_path: Path of dictionary. Mandatory field if using PPDB as data source\n",
      " |  :param str lang: Language of your text. Default value is 'eng'. For `wordnet`, you can choose lang from this list\n",
      " |      http://compling.hss.ntu.edu.sg/omw/. For `ppdb`, you simply download corresponding langauge pack from\n",
      " |      http://paraphrase.org/#/download.\n",
      " |  :param float aug_p: Percentage of word will be augmented.\n",
      " |  :param int aug_min: Minimum number of word will be augmented.\n",
      " |  :param int aug_max: Maximum number of word will be augmented. If None is passed, number of augmentation is\n",
      " |      calculated via aup_p. If calculated result from aug_p is smaller than aug_max, will use calculated result from\n",
      " |      aug_p. Otherwise, using aug_max.\n",
      " |  :param list stopwords: List of words which will be skipped from augment operation.\n",
      " |  :param str stopwords_regex: Regular expression for matching words which will be skipped from augment operation.\n",
      " |  :param func tokenizer: Customize tokenization process\n",
      " |  :param func reverse_tokenizer: Customize reverse of tokenization process\n",
      " |  :param bool force_reload: Force reload model to memory when initialize the class.\n",
      " |      Default value is False and suggesting to keep it as False if performance is the consideration.\n",
      " |  :param str name: Name of this augmenter\n",
      " |  \n",
      " |  >>> import nlpaug.augmenter.word as naw\n",
      " |  >>> aug = naw.SynonymAug()\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      SynonymAug\n",
      " |      nlpaug.augmenter.word.word_augmenter.WordAugmenter\n",
      " |      nlpaug.base_augmenter.Augmenter\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, aug_src='wordnet', model_path=None, name='Synonym_Aug', aug_min=1, aug_max=10, aug_p=0.3, lang='eng', stopwords=None, tokenizer=None, reverse_tokenizer=None, stopwords_regex=None, force_reload=False, verbose=0)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __str__(self)\n",
      " |      Return str(self).\n",
      " |  \n",
      " |  skip_aug(self, token_idxes, tokens)\n",
      " |  \n",
      " |  substitute(self, data)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  get_model(aug_src, lang, dict_path, force_reload) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nlpaug.augmenter.word.word_augmenter.WordAugmenter:\n",
      " |  \n",
      " |  align_capitalization(self, src_token, dest_token)\n",
      " |  \n",
      " |  is_stop_words(self, token)\n",
      " |  \n",
      " |  postprocess(self, data)\n",
      " |  \n",
      " |  pre_skip_aug(self, tokens, tuple_idx=None)\n",
      " |  \n",
      " |  preprocess(self, data)\n",
      " |  \n",
      " |  replace_reserve_word_by_stopword(self, text, reserve_word_aug, original_stopwords)\n",
      " |  \n",
      " |  replace_stopword_by_reserved_word(self, text, stopword_reg, reserve_word)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from nlpaug.augmenter.word.word_augmenter.WordAugmenter:\n",
      " |  \n",
      " |  clean(data) from builtins.type\n",
      " |  \n",
      " |  get_word_case(word) from builtins.type\n",
      " |  \n",
      " |  is_duplicate(dataset, data) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from nlpaug.base_augmenter.Augmenter:\n",
      " |  \n",
      " |  augment(self, data, n=1, num_thread=1)\n",
      " |      :param object/list data: Data for augmentation. It can be list of data (e.g. list \n",
      " |          of string or numpy) or single element (e.g. string or numpy). Numpy format only\n",
      " |          supports audio or spectrogram data. For text data, only support string or\n",
      " |          list of string.\n",
      " |      :param int n: Default is 1. Number of unique augmented output. Will be force to 1 \n",
      " |          if input is list of data\n",
      " |      :param int num_thread: Number of thread for data augmentation. Use this option \n",
      " |          when you are using CPU and n is larger than 1\n",
      " |      :return: Augmented data\n",
      " |      \n",
      " |      >>> augmented_data = aug.augment(data)\n",
      " |  \n",
      " |  crop(self, data)\n",
      " |  \n",
      " |  delete(self, data)\n",
      " |  \n",
      " |  evaluate(self)\n",
      " |  \n",
      " |  generate_aug_cnt(self, size, aug_p=None)\n",
      " |  \n",
      " |  generate_aug_idxes(self, inputs)\n",
      " |  \n",
      " |  insert(self, data)\n",
      " |  \n",
      " |  split(self, data)\n",
      " |  \n",
      " |  swap(self, data)\n",
      " |  \n",
      " |  tokenizer(self, tokens)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from nlpaug.base_augmenter.Augmenter:\n",
      " |  \n",
      " |  prob() from builtins.type\n",
      " |  \n",
      " |  sample(x, num=None) from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from nlpaug.base_augmenter.Augmenter:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(naw.SynonymAug())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spam-detector-P2ybB3t6-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
